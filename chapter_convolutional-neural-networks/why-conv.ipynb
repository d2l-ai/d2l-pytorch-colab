{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# De Camadas Totalmente Conectadas às Convoluções\n",
    ":label:`sec_why-conv`\n",
    "\n",
    "\n",
    "Até hoje,\n",
    "os modelos que discutimos até agora\n",
    "permanecem opções apropriadas\n",
    "quando estamos lidando com dados tabulares.\n",
    "Por tabular, queremos dizer que os dados consistem\n",
    "de linhas correspondentes a exemplos\n",
    "e colunas correspondentes a *features*.\n",
    "Com dados tabulares, podemos antecipar\n",
    "que os padrões que buscamos podem envolver\n",
    "interações entre as características,\n",
    "mas não assumimos nenhuma estrutura *a priori*\n",
    "sobre como as características interagem.\n",
    "\n",
    "Às vezes, realmente não temos conhecimento para orientar\n",
    "a construção de arquiteturas mais artesanais.\n",
    "Nestes casos, um MLP\n",
    "pode ser o melhor que podemos fazer.\n",
    "No entanto, para dados perceptivos de alta dimensão,\n",
    "essas redes sem estrutura podem se tornar difíceis de manejar.\n",
    "\n",
    "Por exemplo, vamos voltar ao nosso exemplo de execução\n",
    "de distinguir gatos de cães.\n",
    "Digamos que fazemos um trabalho completo na coleta de dados,\n",
    "coletando um conjunto de dados anotado de fotografias de um megapixel.\n",
    "Isso significa que cada entrada na rede tem um milhão de dimensões.\n",
    "De acordo com nossas discussões sobre custo de parametrização\n",
    "de camadas totalmente conectadas em :numref:`subsec_parameterization-cost-fc-layers`,\n",
    "até mesmo uma redução agressiva para mil dimensões ocultas\n",
    "exigiria uma camada totalmente conectada\n",
    "caracterizada por $10^6 \\times 10^3 = 10^9$ parâmetros.\n",
    "A menos que tenhamos muitas GPUs, um talento\n",
    "para otimização distribuída,\n",
    "e uma quantidade extraordinária de paciência,\n",
    "aprender os parâmetros desta rede\n",
    "pode acabar sendo inviável.\n",
    "\n",
    "Um leitor cuidadoso pode objetar a este argumento\n",
    "na base de que a resolução de um megapixel pode não ser necessária.\n",
    "No entanto, embora possamos ser capazes\n",
    "de escapar com apenas cem mil pixels,\n",
    "nossa camada oculta de tamanho 1000 subestima grosseiramente\n",
    "o número de unidades ocultas que leva\n",
    "para aprender boas representações de imagens,\n",
    "portanto, um sistema prático ainda exigirá bilhões de parâmetros.\n",
    "Além disso, aprender um classificador ajustando tantos parâmetros\n",
    "pode exigir a coleta de um enorme conjunto de dados.\n",
    "E ainda hoje tanto os humanos quanto os computadores são capazes\n",
    "de distinguir gatos de cães muito bem,\n",
    "aparentemente contradizendo essas intuições.\n",
    "Isso ocorre porque as imagens exibem uma estrutura rica\n",
    "que pode ser explorada por humanos\n",
    "e modelos de aprendizado de máquina semelhantes.\n",
    "Redes neurais convolucionais (CNNs) são uma forma criativa\n",
    "que o *machine learning* adotou para explorar\n",
    "algumas das estruturas conhecidas em imagens naturais.\n",
    "\n",
    "\n",
    "## Invariância\n",
    "\n",
    "Imagine que você deseja detectar um objeto em uma imagem.\n",
    "Parece razoável que qualquer método\n",
    "que usamos para reconhecer objetos não deveria se preocupar demais\n",
    "com a localização precisa do objeto na imagem.\n",
    "Idealmente, nosso sistema deve explorar esse conhecimento.\n",
    "Os porcos geralmente não voam e os aviões geralmente não nadam.\n",
    "No entanto, devemos ainda reconhecer\n",
    "um porco era aquele que aparecia no topo da imagem.\n",
    "Podemos tirar alguma inspiração aqui\n",
    "do jogo infantil \"Cadê o Wally\"\n",
    "(representado em :numref:`img_waldo`).\n",
    "O jogo consiste em várias cenas caóticas\n",
    "repletas de atividades.\n",
    "Wally aparece em algum lugar em cada uma,\n",
    "normalmente à espreita em algum local improvável.\n",
    "O objetivo do leitor é localizá-lo.\n",
    "Apesar de sua roupa característica,\n",
    "isso pode ser surpreendentemente difícil,\n",
    "devido ao grande número de distrações.\n",
    "No entanto, *a aparência do Wally*\n",
    "não depende de *onde o Wally está localizado*.\n",
    "Poderíamos varrer a imagem com um detector Wally\n",
    "que poderia atribuir uma pontuação a cada *patch*,\n",
    "indicando a probabilidade de o *patch* conter Wally.\n",
    "CNNs sistematizam essa ideia de *invariância espacial*,\n",
    "explorando para aprender representações úteis\n",
    "com menos parâmetros.\n",
    "\n",
    "![Uma imagem do jogo \"Onde está Wally\".](../img/where-wally-walker-books.jpg)\n",
    ":width:`400px`\n",
    ":label:`img_waldo`\n",
    "\n",
    "\n",
    "\n",
    "Agora podemos tornar essas intuições mais concretas\n",
    "enumerando alguns desideratos para orientar nosso design\n",
    "de uma arquitetura de rede neural adequada para visão computacional:\n",
    "\n",
    "1. Nas primeiras camadas, nossa rede\n",
    "     deve responder de forma semelhante ao mesmo *patch*,\n",
    "     independentemente de onde aparece na imagem. Este princípio é denominado *invariância da tradução*.\n",
    "1. As primeiras camadas da rede devem se concentrar nas regiões locais,\n",
    "    sem levar em conta o conteúdo da imagem em regiões distantes. Este é o princípio de *localidade*.\n",
    "    Eventualmente, essas representações locais podem ser agregadas\n",
    "    para fazer previsões em todo o nível da imagem.\n",
    "\n",
    "Vamos ver como isso se traduz em matemática.\n",
    "\n",
    "\n",
    "\n",
    "## Restringindo o MLP\n",
    "\n",
    "\n",
    "Para começar, podemos considerar um MLP\n",
    "com imagens bidimensionais $\\mathbf{X}$ como entradas\n",
    "e suas representações ocultas imediatas\n",
    "$\\mathbf{H}$ similarmente representadas como matrizes em matemática e como tensores bidimensionais em código, onde $\\mathbf{X}$ e $\\mathbf{H}$ têm a mesma forma.\n",
    "Deixe isso penetrar.\n",
    "Agora concebemos não apenas as entradas, mas\n",
    "também as representações ocultas como possuidoras de estrutura espacial.\n",
    "\n",
    "Deixe $[\\mathbf{X}]_{i, j}$ e $[\\mathbf{H}]_{i, j}$ denotarem o pixel\n",
    "no local ($i$, $j$)\n",
    "na imagem de entrada e representação oculta, respectivamente.\n",
    "Consequentemente, para que cada uma das unidades ocultas\n",
    "receba entrada de cada um dos pixels de entrada,\n",
    "nós deixaríamos de usar matrizes de peso\n",
    "(como fizemos anteriormente em MLPs)\n",
    "para representar nossos parâmetros\n",
    "como tensores de peso de quarta ordem $\\mathsf{W}$.\n",
    "Suponha que $\\mathbf{U}$ contenha *bias*,\n",
    "poderíamos expressar formalmente a camada totalmente conectada como\n",
    "\n",
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned},$$\n",
    "\n",
    "onde a mudança de $\\mathsf{W}$ para $\\mathsf{V}$ é inteiramente cosmética por enquanto\n",
    "uma vez que existe uma correspondência um-para-um\n",
    "entre coeficientes em ambos os tensores de quarta ordem.\n",
    "Nós simplesmente reindexamos os subscritos $(k, l)$\n",
    "de modo que $k = i+a$ and $l = j+b$.\n",
    "Em outras palavras, definimos $[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$.\n",
    "Os índices $a$ e $b$ ultrapassam os deslocamentos positivos e negativos,\n",
    "cobrindo toda a imagem.\n",
    "Para qualquer localização dada ($i$, $j$) na representação oculta $[\\mathbf{H}]_{i, j}$,\n",
    "calculamos seu valor somando os pixels em $x$,\n",
    "centralizado em torno de $(i, j)$ e ponderado por $[\\mathsf{V}]_{i, j, a, b}$.\n",
    "\n",
    "### Invariância de Tradução\n",
    "\n",
    "Agora vamos invocar o primeiro princípio\n",
    "estabelecido acima: invariância de tradução.\n",
    "Isso implica que uma mudança na entrada $\\mathbf{X}$\n",
    "deve simplesmente levar a uma mudança na representação oculta $\\mathbf{H}$.\n",
    "Isso só é possível se $\\mathsf{V}$ e $\\mathbf{U}$ não dependem realmente de $(i, j)$,\n",
    "ou seja, temos $[\\mathsf{V}]_{i, j, a, b} = [\\mathbf{V}]_{a, b}$ e $\\mathbf{U}$$ é uma constante, digamos $u$.\n",
    "Como resultado, podemos simplificar a definição de $\\mathbf{H}$:\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n",
    "\n",
    "\n",
    "Esta é uma *convolução*!\n",
    "Estamos efetivamente ponderando pixels em $(i+a, j+b)$\n",
    "nas proximidades da localização $(i, j)$ com coeficientes$[\\mathbf{V}]_{a, b}$\n",
    "para obter o valor $[\\mathbf{H}]_{i, j}$.\n",
    "Observe que $[\\mathbf{V}]_{a, b}$ precisa de muito menos coeficientes do que $[\\mathsf{V}]_{i, j, a, b}, pois ele\n",
    "não depende mais da localização na imagem.\n",
    "Fizemos um progresso significativo!\n",
    "\n",
    "###  Localidade\n",
    "\n",
    "Agora, vamos invocar o segundo princípio: localidade.\n",
    "Conforme motivado acima, acreditamos que não devemos ter\n",
    "parecer muito longe do local $(i, j)$\n",
    "a fim de coletar informações relevantes\n",
    "para avaliar o que está acontecendo em $[\\mathbf{H}]_{i, j}$.\n",
    "Isso significa que fora de algum intervalo $|a|> \\Delta$ or $|b| > \\Delta$,\n",
    "devemos definir $[\\mathbf{V}]_{a, b} = 0$.\n",
    "Equivalentemente, podemos reescrever $[\\mathbf{H}]_{i, j}$ como\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n",
    ":eqlabel:`eq_conv-layer`\n",
    "\n",
    "Observe que :eqref:`eq_conv-layer`, em poucas palavras, é uma *camada convolucional*.\n",
    "*Redes neurais convolucionais* (CNNs[^1])\n",
    "são uma família especial de redes neurais que contêm camadas convolucionais.\n",
    "Na comunidade de pesquisa de *deep learning*,\n",
    "$\\mathbf{V}$ é referido como um *kernel de convolução*,\n",
    "um *filtro*, ou simplesmente os *pesos* da camada que são parâmetros frequentemente aprendíveis.\n",
    "Quando a região local é pequena,\n",
    "a diferença em comparação com uma rede totalmente conectada pode ser dramática.\n",
    "Embora anteriormente, pudéssemos ter exigido bilhões de parâmetros\n",
    "para representar apenas uma única camada em uma rede de processamento de imagem,\n",
    "agora precisamos de apenas algumas centenas, sem\n",
    "alterar a dimensionalidade de qualquer\n",
    "as entradas ou as representações ocultas.\n",
    "O preço pago por esta redução drástica de parâmetros\n",
    "é que nossos recursos agora são invariantes de tradução\n",
    "e que nossa camada só pode incorporar informações locais,\n",
    "ao determinar o valor de cada ativação oculta.\n",
    "Todo aprendizado depende da imposição de *bias* indutivos.\n",
    "Quando esses *bias* concordam com a realidade,\n",
    "obtemos modelos com amostras eficientes\n",
    "que generalizam bem para dados invisíveis.\n",
    "Mas é claro, se esses *bias* não concordam com a realidade,\n",
    "por exemplo, se as imagens acabassem não sendo invariantes à tradução,\n",
    "nossos modelos podem ter dificuldade até mesmo para se ajustar aos nossos dados de treinamento.\n",
    "\n",
    "[^1]: *Convolutional Neural Networks.*\n",
    "\n",
    "## Convoluções\n",
    "\n",
    "\n",
    "Antes de prosseguir, devemos revisar brevemente\n",
    "porque a operação acima é chamada de convolução.\n",
    "Em matemática, a *convolução* entre duas funções,\n",
    "digamos que $f, g: \\mathbb{R}^d \\to \\mathbb{R}$ é definida como\n",
    "\n",
    "$$(f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}.$$\n",
    "\n",
    "Ou seja, medimos a sobreposição entre $f$ e $g$\n",
    "quando uma função é \"invertida\" e deslocada por $\\mathbf{x}$.\n",
    "Sempre que temos objetos discretos, a integral se transforma em uma soma.\n",
    "Por exemplo, para vetores do conjunto de vetores dimensionais infinitos somados ao quadrado\n",
    "com o índice acima de $\\mathbb{Z}$, obtemos a seguinte definição:\n",
    "\n",
    "$$(f * g)(i) = \\sum_a f(a) g(i-a).$$\n",
    "\n",
    "Para tensores bidimensionais, temos uma soma correspondente\n",
    "com índices $(a, b)$ para $f$ e $(i-a, j-b)$ para $g$, respectivamente:\n",
    "\n",
    "$$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b).$$\n",
    ":eqlabel:`eq_2d-conv-discrete`\n",
    "\n",
    "Isso é semelhante a :eqref:`eq_conv-layer`, com uma grande diferença.\n",
    "Em vez de usar $(i+a, j+b)$, estamos usando a diferença.\n",
    "Observe, porém, que esta distinção é principalmente cosmética\n",
    "uma vez que sempre podemos combinar a notação entre\n",
    ":eqref:`eq_conv-layer` e :eqref:`eq_2d-conv-discrete`.\n",
    "Nossa definição original em :eqref:`eq_conv-layer` mais apropriadamente\n",
    "descreve uma *correlação cruzada*.\n",
    "Voltaremos a isso na seção seguinte.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## \"Onde está Wally\" Revisitado\n",
    "\n",
    "Voltando ao nosso detector Wally, vamos ver como é.\n",
    "A camada convolucional escolhe janelas de um determinado tamanho\n",
    "e pesa as intensidades de acordo com o filtro $\\mathsf{V}$, conforme demonstrado em :numref:`fig_waldo_mask`.\n",
    "Podemos ter como objetivo aprender um modelo para que\n",
    "onde quer que a \"Wallyneza\" seja mais alta,\n",
    "devemos encontrar um pico nas representações das camadas ocultas.\n",
    "\n",
    "![Detectar Wally.](../img/waldo-mask.jpg)\n",
    ":width:`400px`\n",
    ":label:`fig_waldo_mask`\n",
    "\n",
    "\n",
    "### Canais\n",
    ":label:`subsec_why-conv-channels`\n",
    "\n",
    "Existe apenas um problema com essa abordagem.\n",
    "Até agora, felizmente ignoramos que as imagens consistem\n",
    "de 3 canais: vermelho, verde e azul.\n",
    "Na realidade, as imagens não são objetos bidimensionais\n",
    "mas sim tensores de terceira ordem,\n",
    "caracterizados por uma altura, largura e canal,\n",
    "por exemplo, com forma $1024 \\times 1024 \\times 3$ pixels.\n",
    "Enquanto os dois primeiros desses eixos dizem respeito às relações espaciais,\n",
    "o terceiro pode ser considerado como atribuição\n",
    "uma representação multidimensional para cada localização de pixel.\n",
    "Assim, indexamos $\\mathsf{X}$ como $[\\mathsf{X}]_{i, j, k}$.\n",
    "O filtro convolucional deve se adaptar em conformidade.\n",
    "Em vez de $[\\mathbf{V}]_{a,b}$, agora temos $[\\mathsf{V}]_{a,b,c}$.\n",
    "\n",
    "Além disso, assim como nossa entrada consiste em um tensor de terceira ordem,\n",
    "é uma boa ideia formular de forma semelhante\n",
    "nossas representações ocultas como tensores de terceira ordem $\\mathsf{H}$.\n",
    "Em outras palavras, em vez de apenas ter uma única representação oculta\n",
    "correspondendo a cada localização espacial,\n",
    "queremos todo um vetor de representações ocultas\n",
    "correspondente a cada localização espacial.\n",
    "Poderíamos pensar nas representações ocultas como abrangendo\n",
    "várias grades bidimensionais empilhadas umas sobre as outras.\n",
    "Como nas entradas, às vezes são chamados de *canais*.\n",
    "Eles também são chamados de *mapas de características*,\n",
    "já que cada um fornece um conjunto espacializado\n",
    "de recursos aprendidos para a camada subsequente.\n",
    "Intuitivamente, você pode imaginar que nas camadas inferiores que estão mais próximas das entradas,\n",
    "alguns canais podem se tornar especializados para reconhecer bordas enquanto\n",
    "outros podem reconhecer texturas.\n",
    "\n",
    "\n",
    "Para suportar canais múltiplos em ambas as entradas ($\\mathsf{X}$) e representações ocultas ($\\mathsf{H}$),\n",
    "podemos adicionar uma quarta coordenada a  $\\mathsf{V}$: $[\\mathsf{V}]_{a, b, c, d}$.\n",
    "Juntando tudo, temos:\n",
    "\n",
    "$$[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c},$$\n",
    ":eqlabel:`eq_conv-layer-channels`\n",
    "\n",
    "\n",
    "onde $d$ indexa os canais de saída nas representações ocultas $\\mathsf{H}$. A camada convolucional subsequente irá tomar um tensor de terceira ordem, $\\mathsf{H}$, como entrada.\n",
    "Sendo mais geral,\n",
    ":eqref:`eq_conv-layer-channels` é\n",
    "a definição de uma camada convolucional para canais múltiplos, onde $\\mathsf{V}$ é um *kernel* ou filtro da camada.\n",
    "\n",
    "Ainda existem muitas operações que precisamos abordar.\n",
    "Por exemplo, precisamos descobrir como combinar todas as representações ocultas\n",
    "para uma única saída, por exemplo, se há um Wally *em qualquer lugar* da imagem.\n",
    "Também precisamos decidir como computar as coisas de forma eficiente,\n",
    "como combinar várias camadas,\n",
    "funções de ativação apropriadas,\n",
    "e como fazer escolhas de design razoáveis\n",
    "para produzir redes eficazes na prática.\n",
    "Voltaremos a essas questões no restante do capítulo.\n",
    "\n",
    "## Resumo\n",
    "\n",
    "* A invariância da tradução nas imagens implica que todas as manchas de uma imagem serão tratadas da mesma maneira.\n",
    "* Localidade significa que apenas uma pequena vizinhança de pixels será usada para calcular as representações ocultas correspondentes.\n",
    "* No processamento de imagem, as camadas convolucionais geralmente requerem muito menos parâmetros do que as camadas totalmente conectadas.\n",
    "* CNNS são uma família especial de redes neurais que contêm camadas convolucionais.\n",
    "* Os canais de entrada e saída permitem que nosso modelo capture vários aspectos de uma imagem em cada localização espacial.\n",
    "\n",
    "## Exercícios\n",
    "\n",
    "1. Suponha que o tamanho do *kernel* de convolução seja $\\Delta = 0$.\n",
    "    Mostre que, neste caso, o *kernel* de convolução\n",
    "    implementa um MLP independentemente para cada conjunto de canais.\n",
    "1. Por que a invariância da tradução pode não ser uma boa ideia, afinal?\n",
    "1. Com quais problemas devemos lidar ao decidir como tratar representações ocultas correspondentes a localizações de pixels\n",
    "    na fronteira de uma imagem?\n",
    "1. Descreva uma camada convolucional análoga para áudio.\n",
    "1. Você acha que as camadas convolucionais também podem ser aplicáveis para dados de texto?\n",
    "    Por que ou por que não?\n",
    "1. Prove que $f * g = g * f$.\n",
    "\n",
    "[Discussions](https://discuss.d2l.ai/t/64)\n",
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbLTE5NzY4MTMyNzYsMjAwOTM3MTA1MCw5NT\n",
    "cwMjU3MDUsLTE5MjE4MTMwODgsMjQyMjkwODk3LC0xNTg0MzI4\n",
    "NzgwLC0xMTIyNTk3ODYzLC0xNjU3MzY2MjUwLDE2NzM2MjU2MT\n",
    "AsLTEyOTkyNDE5NjRdfQ==\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}