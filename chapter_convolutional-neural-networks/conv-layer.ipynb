{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install d2l==0.17.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Convolução para Imagens\n",
    ":label:`sec_conv_layer`\n",
    "\n",
    "Agora que entendemos como as camadas convolucionais funcionam na teoria,\n",
    "estamos prontos para ver como eles funcionam na prática.\n",
    "Com base na nossa motivação de redes neurais convolucionais\n",
    "como arquiteturas eficientes para explorar a estrutura em dados de imagem,\n",
    "usamos imagens como nosso exemplo de execução.\n",
    "\n",
    "\n",
    "## A Operação de Correlação Cruzada\n",
    "\n",
    "\n",
    "Lembre-se de que, estritamente falando, as camadas convolucionais\n",
    "são um nome impróprio, uma vez que as operações que elas expressam\n",
    "são descritos com mais precisão como correlações cruzadas.\n",
    "Com base em nossas descrições de camadas convolucionais em :numref:`sec_why-conv`,\n",
    "em tal camada, um tensor de entrada\n",
    "e um tensor de *kernel* são combinados\n",
    "para produzir um tensor de saída por meio de uma operação de correlação cruzada.\n",
    "\n",
    "Vamos ignorar os canais por enquanto e ver como isso funciona\n",
    "com dados bidimensionais e representações ocultas.\n",
    "Em :numref:`fig_correlation`,\n",
    "a entrada é um tensor bidimensional\n",
    "com altura de 3 e largura de 3.\n",
    "Marcamos a forma do tensor como $3 \\times 3$ or ($3$, $3$).\n",
    "A altura e a largura do *kernel* são 2.\n",
    "A forma da *janela do kernel* (ou *janela de convolução*)\n",
    "é dada pela altura e largura do *kernel*\n",
    "(aqui é $2 \\times 2$).\n",
    "\n",
    "![Operação de correlação cruzada bidimensional. As partes sombreadas são o primeiro elemento de saída, bem como os elementos tensores de entrada e *kernel* usados para o cálculo de saída: $0\\times0+1\\times1+3\\times2+4\\times3=19$.](http://d2l.ai/_images/correlation.svg)\n",
    ":label:`fig_correlation`\n",
    "\n",
    "Na operação de correlação cruzada bidimensional,\n",
    "começamos com a janela de convolução posicionada\n",
    "no canto superior esquerdo do tensor de entrada\n",
    "e o deslizamos pelo tensor de entrada,\n",
    "ambos da esquerda para a direita e de cima para baixo.\n",
    "Quando a janela de convolução desliza para uma determinada posição,\n",
    "o subtensor de entrada contido nessa janela\n",
    "e o tensor do *kernel* são multiplicados elemento a elemento\n",
    "e o tensor resultante é resumido\n",
    "produzindo um único valor escalar.\n",
    "Este resultado fornece o valor do tensor de saída\n",
    "no local correspondente.\n",
    "Aqui, o tensor de saída tem uma altura de 2 e largura de 2\n",
    "e os quatro elementos são derivados de\n",
    "a operação de correlação cruzada bidimensional:\n",
    "\n",
    "$$\n",
    "0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\\n",
    "1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n",
    "3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n",
    "4\\times0+5\\times1+7\\times2+8\\times3=43.\n",
    "$$\n",
    "\n",
    "Observe que ao longo de cada eixo, o tamanho da saída\n",
    "é ligeiramente menor que o tamanho de entrada.\n",
    "Como o *kernel* tem largura e altura maiores que um,\n",
    "só podemos calcular corretamente a correlação cruzada\n",
    "para locais onde o *kernel* se encaixa totalmente na imagem,\n",
    "o tamanho da saída é dado pelo tamanho da entrada $n_h \\times n_w$\n",
    "menos o tamanho do *kernel* de convolução $k_h \\times k_w$\n",
    "através da\n",
    "\n",
    "$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\n",
    "\n",
    "Este é o caso, pois precisamos de espaço suficiente\n",
    "para \"deslocar\" o *kernel* de convolução na imagem.\n",
    "Mais tarde, veremos como manter o tamanho inalterado\n",
    "preenchendo a imagem com zeros em torno de seu limite\n",
    "para que haja espaço suficiente para mudar o *kernel*.\n",
    "Em seguida, implementamos este processo na função `corr2d`,\n",
    "que aceita um tensor de entrada `X` e um tensor de *kernel* `K`\n",
    "e retorna um tensor de saída `Y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "Podemos construir o tensor de entrada `X` e o tensor do kernel` K`\n",
    "from :numref:`fig_correlation`\n",
    "para validar o resultado da implementação acima\n",
    "da operação de correlação cruzada bidimensional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "## Camadas Convolucionais\n",
    "\n",
    "\n",
    "Uma camada convolucional correlaciona a entrada e o *kernel*\n",
    "e adiciona um *bias* escalar para produzir uma saída.\n",
    "Os dois parâmetros de uma camada convolucional\n",
    "são o *kernel* e o *bias* escalar.\n",
    "Ao treinar modelos com base em camadas convolucionais,\n",
    "normalmente inicializamos os *kernels* aleatoriamente,\n",
    "assim como faríamos com uma camada totalmente conectada.\n",
    "\n",
    "Agora estamos prontos para implementar uma camada convolucional bidimensional\n",
    "com base na função `corr2d` definida acima.\n",
    "Na função construtora `__init__`,\n",
    "declaramos `weight` e` bias` como os dois parâmetros do modelo.\n",
    "A função de propagação direta\n",
    "chama a função `corr2d` e adiciona o viés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "Na convolução\n",
    "$h \\times w$ \n",
    "ou um *kernel* de convolução $h \\times w$\n",
    "a altura e a largura do *kernel* de convolução são $h$ e $w$, respectivamente.\n",
    "Também nos referimos a\n",
    "uma camada convolucional com um kernel de convolução $h \\times w$\n",
    "simplesmente como uma camada convolucional $h \\times w$\n",
    "\n",
    "\n",
    "## Detecção de Borda de Objeto em Imagens\n",
    "\n",
    "Vamos analisar uma aplicação simples de uma camada convolucional:\n",
    "detectar a borda de um objeto em uma imagem\n",
    "encontrando a localização da mudança de pixel.\n",
    "Primeiro, construímos uma \"imagem\" de $6\\times 8$ pixels.\n",
    "As quatro colunas do meio são pretas (0) e as demais são brancas (1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "Em seguida, construímos um kernel `K` com uma altura de 1 e uma largura de 2.\n",
    "Quando realizamos a operação de correlação cruzada com a entrada,\n",
    "se os elementos horizontalmente adjacentes forem iguais,\n",
    "a saída é 0. Caso contrário, a saída é diferente de zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "Estamos prontos para realizar a operação de correlação cruzada\n",
    "com os argumentos `X` (nossa entrada) e` K` (nosso kernel).\n",
    "Como você pode ver, detectamos 1 para a borda do branco ao preto\n",
    "e -1 para a borda do preto ao branco.\n",
    "Todas as outras saídas assumem o valor 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "Agora podemos aplicar o kernel à imagem transposta.\n",
    "Como esperado, ele desaparece. O kernel `K` detecta apenas bordas verticais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(), K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## Aprendendo um Kernel\n",
    "\n",
    "\n",
    "Projetar um detector de borda por diferenças finitas `[1, -1]` é legal\n",
    "se sabemos que é exatamente isso que estamos procurando.\n",
    "No entanto, quando olhamos para *kernels* maiores,\n",
    "e considere camadas sucessivas de convoluções,\n",
    "pode ser impossível especificar\n",
    "exatamente o que cada filtro deve fazer manualmente.\n",
    "\n",
    "Agora vamos ver se podemos aprender o *kernel* que gerou `Y` de` X`\n",
    "olhando apenas para os pares de entrada--saída.\n",
    "Primeiro construímos uma camada convolucional\n",
    "e inicializamos seu *kernel* como um tensor aleatório.\n",
    "A seguir, em cada iteração, usaremos o erro quadrático\n",
    "para comparar `Y` com a saída da camada convolucional.\n",
    "Podemos então calcular o gradiente para atualizar o *kernel*.\n",
    "Por uma questão de simplicidade,\n",
    "na sequência\n",
    "nós usamos a classe embutida\n",
    "para camadas convolucionais bidimensionais\n",
    "e ignorar o *bias*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2, loss 9.670\n",
      "batch 4, loss 2.786\n",
      "batch 6, loss 0.944\n",
      "batch 8, loss 0.354\n",
      "batch 10, loss 0.139\n"
     ]
    }
   ],
   "source": [
    "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
    "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
    "conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# The two-dimensional convolutional layer uses four-dimensional input and\n",
    "# output in the format of (example channel, height, width), where the batch\n",
    "# size (number of examples in the batch) and the number of channels are both 1\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # Update the kernel\n",
    "    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'batch {i + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "Observe que o erro caiu para um valor pequeno após 10 iterações. Agora daremos uma olhada no tensor do *kernel* que aprendemos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0265, -0.9505]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "Indeed, the learned kernel tensor is remarkably close\n",
    "to the kernel tensor `K` we defined earlier.\n",
    "\n",
    "## Correlação Cruzada e Convolução\n",
    "\n",
    "\n",
    "Lembre-se de nossa observação de :numref:`sec_why-conv` da correspondência\n",
    "entre as operações de correlação cruzada e convolução.\n",
    "Aqui, vamos continuar a considerar as camadas convolucionais bidimensionais.\n",
    "E se essas camadas\n",
    "realizar operações de convolução estritas\n",
    "conforme definido em :eqref:`eq_2d-conv-discrete`\n",
    "em vez de correlações cruzadas?\n",
    "Para obter a saída da operação de *convolução* estrita, precisamos apenas inverter o tensor do *kerne*l bidimensional tanto horizontal quanto verticalmente e, em seguida, executar a operação de *correlação cruzada* com o tensor de entrada.\n",
    "\n",
    "É digno de nota que, uma vez que os *kernels* são aprendidos a partir de dados no aprendizado profundo,\n",
    "as saídas das camadas convolucionais permanecem inalteradas\n",
    "não importa se tais camadas\n",
    "executam\n",
    "as operações de convolução estrita\n",
    "ou as operações de correlação cruzada.\n",
    "\n",
    "\n",
    "Para ilustrar isso, suponha que uma camada convolucional execute *correlação cruzada* e aprenda o *kernel* em :numref:`fig_correlation`, que é denotado como a matriz $\\mathbf{K}$ aqui.\n",
    "Supondo que outras condições permaneçam inalteradas,\n",
    "quando esta camada executa *convolução* estrita em vez disso,\n",
    "o *kernel* aprendido $\\mathbf{K}'$ será o mesmo que $\\mathbf{K}$\n",
    "depois que $\\mathbf{K}'$ is  é\n",
    "invertido horizontalmente e verticalmente.\n",
    "Quer dizer,\n",
    "quando a camada convolucional\n",
    "executa *convolução* estrita\n",
    "para a entrada em :numref:`fig_correlation`\n",
    "e $\\mathbf{K}'$,\n",
    "a mesma saída em :numref:`fig_correlation`\n",
    "(correlação cruzada da entrada e $\\mathbf{K}$)\n",
    "será obtida.\n",
    "\n",
    "De acordo com a terminologia padrão da literatura de *deep learning*,\n",
    "continuaremos nos referindo à operação de correlação cruzada\n",
    "como uma convolução, embora, estritamente falando, seja ligeiramente diferente.\n",
    "Além do mais,\n",
    "usamos o termo *elemento* para nos referirmos a\n",
    "uma entrada (ou componente) de qualquer tensor que representa uma representação de camada ou um *kernel* de convolução.\n",
    "\n",
    "\n",
    "## Mapa de Características e Campo Receptivo\n",
    "\n",
    "\n",
    "Conforme descrito em :numref:`subsec_why-conv-channels`,\n",
    "a saída da camada convolucional em\n",
    ":numref:`fig_correlation`\n",
    "às vezes é chamada de *mapa de características*,\n",
    "pois pode ser considerado como\n",
    "as representações aprendidas (características)\n",
    "nas dimensões espaciais (por exemplo, largura e altura)\n",
    "para a camada subsequente.\n",
    "Nas CNNs,\n",
    "para qualquer elemento $x$ de alguma camada,\n",
    "seu *campo receptivo* refere-se a\n",
    "todos os elementos (de todas as camadas anteriores)\n",
    "que pode afetar o cálculo de $x$\n",
    "durante a propagação direta.\n",
    "Observe que o campo receptivo\n",
    "pode ser maior do que o tamanho real da entrada.\n",
    "\n",
    "Vamos continuar a usar :numref:`fig_correlation` para explicar o campo receptivo.\n",
    "Dado o *kernel* de convolução $2 \\times 2$\n",
    "o campo receptivo do elemento de saída sombreado (de valor $19$)\n",
    "são\n",
    "os quatro elementos na parte sombreada da entrada.\n",
    "Agora, vamos denotar a saída $2 \\times 2$\n",
    "como $\\mathbf{Y}$\n",
    "e considere uma CNN mais profunda\n",
    "com uma camada convolucional adicional $2 \\times 2$ que leva $\\mathbf{Y}$\n",
    "como sua entrada, produzindo\n",
    "um único elemento $z$.\n",
    "Nesse caso,\n",
    "o campo receptivo de $z$\n",
    "em $\\mathbf{Y}$ inclui todos os quatro elementos de $\\mathbf{Y}$,\n",
    "enquanto\n",
    "o campo receptivo\n",
    "na entrada inclui todos os nove elementos de entrada.\n",
    "Por isso,\n",
    "quando qualquer elemento em um mapa de recursos\n",
    "precisa de um campo receptivo maior\n",
    "para detectar recursos de entrada em uma área mais ampla,\n",
    "podemos construir uma rede mais profunda.\n",
    "\n",
    "\n",
    "\n",
    "## Resumo\n",
    "\n",
    "* O cálculo central de uma camada convolucional bidimensional é uma operação de correlação cruzada bidimensional. Em sua forma mais simples, isso executa uma operação de correlação cruzada nos dados de entrada bidimensionais e no *kernel* e, em seguida, adiciona um *bias*.\n",
    "* Podemos projetar um *kernel* para detectar bordas em imagens.\n",
    "* Podemos aprender os parâmetros do *kernel* a partir de dados.\n",
    "* Com os *kernels* aprendidos a partir dos dados, as saídas das camadas convolucionais permanecem inalteradas, independentemente das operações realizadas por essas camadas (convolução estrita ou correlação cruzada).\n",
    "* Quando qualquer elemento em um mapa de características precisa de um campo receptivo maior para detectar características mais amplas na entrada, uma rede mais profunda pode ser considerada.\n",
    "\n",
    "\n",
    "## Exercícios\n",
    "\n",
    "1. Construa uma imagem `X` com bordas diagonais.\n",
    "     1. O que acontece se você aplicar o *kernel* `K` nesta seção a ele?\n",
    "     1. O que acontece se você transpõe `X`?\n",
    "     1. O que acontece se você transpõe `K`?\n",
    "1. Quando você tenta encontrar automaticamente o gradiente para a classe `Conv2D` que criamos, que tipo de mensagem de erro você vê?\n",
    "1. Como você representa uma operação de correlação cruzada como uma multiplicação de matriz, alterando os tensores de entrada e *kernel*?\n",
    "1. Projete alguns *kernels* manualmente.\n",
    "     1. Qual é a forma de um *kernel* para a segunda derivada?\n",
    "     1. Qual é o *kernel* de uma integral?\n",
    "     1. Qual é o tamanho mínimo de um *kernel* para obter uma derivada de grau $d$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/66)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbMTczNzg0NzMzNywxMjA2NTU0NTU3LC0xNj\n",
    "c3ODMxMzQ3LC0xOTg4NjQzNDc1LC0xODE4NDc0NzM1LC0xNDk0\n",
    "NjAxMTEyLC0yNDIxOTgyNzcsLTY3NDg1MTc2OSw1NTkxMzU0NT\n",
    "AsMTk4NDk3OTc5N119\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}