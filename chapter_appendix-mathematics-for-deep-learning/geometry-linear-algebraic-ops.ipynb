{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install d2l==0.17.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Operações de Geometria e Álgebra Linear\n",
    ":label:`sec_geometry-linear-algebraic-ops`\n",
    "\n",
    "Em :numref:`sec_linear-algebra`, encontramos os fundamentos da álgebra linear e vimos como ela poderia ser usada para expressar operações comuns para transformar nossos dados.\n",
    "A álgebra linear é um dos principais pilares matemáticos subjacentes a grande parte do trabalho que fazemos no *deep learning* e no *machine learning* de forma mais ampla.\n",
    "Embora :numref:`sec_linear-algebra` contenha maquinário suficiente para comunicar a mecânica dos modelos modernos de aprendizado profundo, há muito mais sobre o assunto.\n",
    "Nesta seção, iremos mais fundo, destacando algumas interpretações geométricas de operações de álgebra linear e introduzindo alguns conceitos fundamentais, incluindo de autovalores e autovetores.\n",
    "\n",
    "## Geometria Vetorial\n",
    "Primeiro, precisamos discutir as duas interpretações geométricas comuns de vetores,\n",
    "como pontos ou direções no espaço.\n",
    "Fundamentalmente, um vetor é uma lista de números, como a lista Python abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "v = [1, 7, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "Os matemáticos geralmente escrevem isso como um vetor *coluna* ou *linha*, ou seja, como\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix}1\\\\7\\\\0\\\\1\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "ou\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^\\top = \\begin{bmatrix}1 & 7 & 0 & 1\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "Muitas vezes têm interpretações diferentes,\n",
    "onde os exemplos de dados são vetores de coluna\n",
    "e os pesos usados para formar somas ponderadas são vetores de linha.\n",
    "No entanto, pode ser benéfico ser flexível.\n",
    "Como descrevemos em :numref:`sec_linear-algebra`,\n",
    "embora a orientação padrão de um único vetor seja um vetor coluna,\n",
    "para qualquer matriz que representa um conjunto de dados tabular,\n",
    "tratando cada exemplo de dados como um vetor de linha\n",
    "na matriz\n",
    "é mais convencional.\n",
    "\n",
    "Dado um vetor, a primeira interpretação\n",
    "que devemos dar é como um ponto no espaço.\n",
    "Em duas ou três dimensões, podemos visualizar esses pontos\n",
    "usando os componentes dos vetores para definir\n",
    "a localização dos pontos no espaço comparada\n",
    "a uma referência fixa chamada *origem*. Isso pode ser visto em :numref:`fig_grid`.\n",
    "\n",
    "![Uma ilustração da visualização de vetores como pontos no plano. O primeiro componente do vetor fornece a coordenada $x$, o segundo componente fornece a coordenada $y$. As dimensões superiores são análogas, embora muito mais difíceis de visualizar.](../img/grid-points.svg)\n",
    ":label:`fig_grid`\n",
    "\n",
    "\n",
    "Esse ponto de vista geométrico nos permite considerar o problema em um nível mais abstrato.\n",
    "Não mais confrontado com algum problema aparentemente intransponível\n",
    "como classificar fotos como gatos ou cachorros,\n",
    "podemos começar a considerar as tarefas abstratamente\n",
    "como coleções de pontos no espaço e retratando a tarefa\n",
    "como descobrir como separar dois grupos distintos de pontos.\n",
    "\n",
    "Paralelamente, existe um segundo ponto de vista\n",
    "que as pessoas costumam tomar de vetores: como direções no espaço.\n",
    "Não podemos apenas pensar no vetor $\\mathbf{v} = [3,2]^\\top$\n",
    "como a localização $3$ unidades à direita e $2$ unidades acima da origem,\n",
    "também podemos pensar nisso como a própria direção\n",
    "para mover $3$ passos para a direita e $2$ para cima.\n",
    "Desta forma, consideramos todos os vetores da figura :numref:`fig_arrow` iguais.\n",
    "\n",
    "![Qualquer vetor pode ser visualizado como uma seta no plano. Nesse caso, todo vetor desenhado é uma representação do vetor $(3,2)^\\top$.](../img/par-vec.svg)\n",
    ":label:`fig_arrow`\n",
    "\n",
    "Um dos benefícios dessa mudança é que\n",
    "podemos dar sentido visual ao ato de adição de vetores.\n",
    "Em particular, seguimos as instruções dadas por um vetor,\n",
    "e então siga as instruções dadas pelo outro, como pode ser visto em :numref:`fig_add-vec`.\n",
    "\n",
    "![Podemos visualizar a adição de vetores seguindo primeiro um vetor e depois outro.](../img/vec-add.svg)\n",
    ":label:`fig_add-vec`\n",
    "\n",
    "A subtração de vetores tem uma interpretação semelhante.\n",
    "Considerando a identidade que $\\mathbf{u} = \\mathbf{v} + (\\mathbf{u}-\\mathbf{v})$,\n",
    "vemos que o vetor $\\mathbf{u}-\\mathbf{v}$ é a direção\n",
    "que nos leva do ponto $\\mathbf{v}$ ao ponto $\\mathbf{u}$.\n",
    "\n",
    "\n",
    "## Produto Escalar e Ângulos\n",
    "Como vimos em :numref:`sec_linear-algebra`,\n",
    "se tomarmos dois vetores de coluna $\\mathbf{u}$ and $\\mathbf{v}$,\n",
    "podemos formar seu produto escalar computando:\n",
    "\n",
    "$$\\mathbf{u}^\\top\\mathbf{v} = \\sum_i u_i\\cdot v_i.$$\n",
    ":eqlabel:`eq_dot_def`\n",
    "\n",
    "Porque :eqref:`eq_dot_def` é simétrico, iremos espelhar a notação\n",
    "de multiplicação clássica e escrita\n",
    "\n",
    "$$\n",
    "\\mathbf{u}\\cdot\\mathbf{v} = \\mathbf{u}^\\top\\mathbf{v} = \\mathbf{v}^\\top\\mathbf{u},\n",
    "$$\n",
    "\n",
    "para destacar o fato de que a troca da ordem dos vetores produzirá a mesma resposta.\n",
    "\n",
    "The dot product :eqref:`eq_dot_def` also admits a geometric interpretation: it is closely related to the angle between two vectors.  Consider the angle shown in :numref:`fig_angle`.\n",
    "\n",
    "![Entre quaisquer dois vetores no plano, existe um ângulo bem definido $\\theta$. Veremos que esse ângulo está intimamente ligado ao produto escalar.](../img/vec-angle.svg)\n",
    ":label:`fig_angle`\n",
    "\n",
    "Para começar, vamos considerar dois vetores específicos:\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = (r,0) \\; \\text{and} \\; \\mathbf{w} = (s\\cos(\\theta), s \\sin(\\theta)).\n",
    "$$\n",
    "\n",
    "O vetor $\\mathbf{v}$ tem comprimento $r$ e corre paralelo ao eixo $x$,\n",
    "e o vetor $\\mathbf{w}$ tem comprimento $s$ e está no ângulo $\\theta$ com o eixo $x$.\n",
    "Se calcularmos o produto escalar desses dois vetores, vemos que\n",
    "\n",
    "$$\n",
    "\\mathbf{v}\\cdot\\mathbf{w} = rs\\cos(\\theta) = \\|\\mathbf{v}\\|\\|\\mathbf{w}\\|\\cos(\\theta).\n",
    "$$\n",
    "\n",
    "Com alguma manipulação algébrica simples, podemos reorganizar os termos para obter\n",
    "\n",
    "$$\n",
    "\\theta = \\arccos\\left(\\frac{\\mathbf{v}\\cdot\\mathbf{w}}{\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|}\\right).\n",
    "$$\n",
    "\n",
    "Em suma, para esses dois vetores específicos,\n",
    "o produto escalar combinado com as normas nos informa o ângulo entre os dois vetores. Este mesmo fato é verdade em geral. Não iremos derivar a expressão aqui, no entanto,\n",
    "se considerarmos escrever $\\|\\mathbf{v} - \\mathbf{w}\\|^2$ de duas maneiras:\n",
    "um com o produto escalar e o outro geometricamente usando a lei dos cossenos,\n",
    "podemos obter o relacionamento completo.\n",
    "Na verdade, para quaisquer dois vetores $\\mathbf{v}$ e $\\mathbf{w}$,\n",
    "o ângulo entre os dois vetores é\n",
    "\n",
    "$$\\theta = \\arccos\\left(\\frac{\\mathbf{v}\\cdot\\mathbf{w}}{\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|}\\right).$$\n",
    ":eqlabel:`eq_angle_forumla`\n",
    "\n",
    "\n",
    "Este é um bom resultado, pois nada no cálculo faz referência a duas dimensões.\n",
    "Na verdade, podemos usar isso em três ou três milhões de dimensões sem problemas.\n",
    "\n",
    "Como um exemplo simples, vamos ver como calcular o ângulo entre um par de vetores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4190)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython import display\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def angle(v, w):\n",
    "    return torch.acos(v.dot(w) / (torch.norm(v) * torch.norm(w)))\n",
    "\n",
    "angle(torch.tensor([0, 1, 2], dtype=torch.float32), torch.tensor([2.0, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "Não o usaremos agora, mas é útil saber\n",
    "que iremos nos referir a vetores para os quais o ângulo é $\\pi/2$\n",
    "(ou equivalentemente $90^{\\circ}$) como sendo *ortogonal*.\n",
    "Examinando a equação acima, vemos que isso acontece quando $\\theta = \\pi/2$,\n",
    "que é a mesma coisa que $\\cos(\\theta) = 0$.\n",
    "A única maneira de isso acontecer é se o produto escalar em si for zero,\n",
    "e dois vetores são ortogonais se e somente se $\\mathbf{v}\\cdot\\mathbf{w} = 0$.\n",
    "Esta será uma fórmula útil para compreender objetos geometricamente.\n",
    "\n",
    "É razoável perguntar: por que calcular o ângulo é útil?\n",
    "A resposta vem no tipo de invariância que esperamos que os dados tenham.\n",
    "Considere uma imagem e uma imagem duplicada,\n",
    "onde cada valor de pixel é o mesmo, mas com $10\\%$ do brilho.\n",
    "Os valores dos pixels individuais estão geralmente longe dos valores originais.\n",
    "Assim, se computarmos a distância entre a imagem original e a mais escura,\n",
    "a distância pode ser grande.\n",
    "No entanto, para a maioria dos aplicativos de ML, o *conteúdo* é o mesmo --- ainda é\n",
    "uma imagem de um gato no que diz respeito a um classificador gato / cão.\n",
    "No entanto, se considerarmos o ângulo, não é difícil ver\n",
    "que para qualquer vetor $\\mathbf{v}$, o ângulo\n",
    "entre $\\mathbf{v}$ e $0.1\\cdot\\mathbf{v}$ é zero.\n",
    "Isso corresponde ao fato de que os vetores de escala\n",
    "mantém a mesma direção e apenas altera o comprimento.\n",
    "O ângulo considera a imagem mais escura idêntica.\n",
    "\n",
    "Exemplos como este estão por toda parte.\n",
    "No texto, podemos querer que o tópico seja discutido\n",
    "para não mudar se escrevermos o dobro do tamanho do documento que diz a mesma coisa.\n",
    "Para algumas codificações (como contar o número de ocorrências de palavras em algum vocabulário), isso corresponde a uma duplicação do vetor que codifica o documento,\n",
    "então, novamente, podemos usar o ângulo.\n",
    "\n",
    "### Semelhança de Cosseno\n",
    "Em contextos de ML onde o ângulo é empregado\n",
    "para medir a proximidade de dois vetores,\n",
    "os profissionais adotam o termo *semelhança de cosseno*\n",
    "para se referir à porção\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{\\mathbf{v}\\cdot\\mathbf{w}}{\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|}.\n",
    "$$\n",
    "\n",
    "O cosseno assume um valor máximo de $1$\n",
    "quando os dois vetores apontam na mesma direção,\n",
    "um valor mínimo de $-1$ quando apontam em direções opostas,\n",
    "e um valor de $0$ quando os dois vetores são ortogonais.\n",
    "Observe que se os componentes de vetores de alta dimensão\n",
    "são amostrados aleatoriamente com $0$ médio,\n",
    "seu cosseno será quase sempre próximo a $0$.\n",
    "\n",
    "\n",
    "## Hiperplanos\n",
    "\n",
    "\n",
    "Além de trabalhar com vetores, outro objeto-chave\n",
    "que você deve entender para ir longe na álgebra linear\n",
    "é o *hiperplano*, uma generalização para dimensões superiores\n",
    "de uma linha (duas dimensões) ou de um plano (três dimensões).\n",
    "Em um espaço vetorial $d$-dimensional, um hiperplano tem $d-1$ dimensões\n",
    "e divide o espaço em dois meios-espaços.\n",
    "\n",
    "Vamos começar com um exemplo.\n",
    "Suponha que temos um vetor coluna $\\mathbf{w}=[2,1]^\\top$.  Queremos saber, \"quais são os pontos $\\mathbf{v}$ com $\\mathbf{w}\\cdot\\mathbf{v} = 1$?\"\n",
    "Ao relembrar a conexão entre produtos escalares e ângulos acima :eqref:`eq_angle_forumla`,\n",
    "podemos ver que isso é equivalente a\n",
    "$$\n",
    "\\|\\mathbf{v}\\|\\|\\mathbf{w}\\|\\cos(\\theta) = 1 \\; \\iff \\; \\|\\mathbf{v}\\|\\cos(\\theta) = \\frac{1}{\\|\\mathbf{w}\\|} = \\frac{1}{\\sqrt{5}}.\n",
    "$$\n",
    "\n",
    "![Relembrando a trigonometria, vemos que a fórmula $\\|\\mathbf{v}\\|\\cos(\\theta)$ é o comprimento da projeção do vetor $\\mathbf{v}$ na direção de $\\mathbf{w}$](../img/proj-vec.svg)\n",
    ":label:`fig_vector-project`\n",
    "\n",
    "Se considerarmos o significado geométrico desta expressão,\n",
    "vemos que isso é equivalente a dizer\n",
    "que o comprimento da projeção de $\\mathbf{v}$\n",
    "na direção de $\\mathbf{w}$ é exatamente $1/\\|\\mathbf{w}\\|$,  como é mostrado em :numref:`fig_vector-project`.\n",
    "O conjunto de todos os pontos onde isso é verdade é uma linha\n",
    "perpendicularmente ao vetor $\\mathbf{w}$.\n",
    "Se quiséssemos, poderíamos encontrar a equação para esta linha\n",
    "e veja que é $2x + y = 1$ ou equivalentemente $y = 1 - 2x$.\n",
    "\n",
    "Se agora olharmos para o que acontece quando perguntamos sobre o conjunto de pontos com\n",
    "$\\mathbf{w}\\cdot\\mathbf{v} > 1$ ou $\\mathbf{w}\\cdot\\mathbf{v} < 1$,\n",
    "podemos ver que estes são casos em que as projeções\n",
    "são maiores ou menores que $1/\\|\\mathbf{w}\\|$, respectivamente.\n",
    "Portanto, essas duas desigualdades definem os dois lados da linha.\n",
    "Desta forma, descobrimos uma maneira de cortar nosso espaço em duas metades,\n",
    "onde todos os pontos de um lado têm produto escalar abaixo de um limite,\n",
    "e o outro lado acima como vemos em :numref:`fig_space-division`.\n",
    "\n",
    "![Se considerarmos agora a versão da desigualdade da expressão, vemos que nosso hiperplano (neste caso: apenas uma linha) separa o espaço em duas metades.](../img/space-division.svg)\n",
    ":label:`fig_space-division`\n",
    "\n",
    "A história em uma dimensão superior é praticamente a mesma.\n",
    "Se agora tomarmos $\\mathbf{w} = [1,2,3]^\\top$\n",
    "e perguntarmos sobre os pontos em três dimensões com $\\mathbf{w}\\cdot\\mathbf{v} = 1$,\n",
    "obtemos um plano perpendicular ao vetor dado $\\mathbf{w}$.\n",
    "As duas desigualdades definem novamente os dois lados do plano como é mostrado em :numref:`fig_higher-division`.\n",
    "\n",
    "![Hiperplanos em qualquer dimensão separam o espaço em duas metades.](../img/space-division-3d.svg)\n",
    ":label:`fig_higher-division`\n",
    "\n",
    "\n",
    "Embora nossa capacidade de visualizar se esgote neste ponto,\n",
    "nada nos impede de fazer isso em dezenas, centenas ou bilhões de dimensões.\n",
    "Isso ocorre frequentemente quando se pensa em modelos aprendidos por máquina.\n",
    "Por exemplo, podemos entender modelos de classificação linear\n",
    "como aqueles de :numref:`sec_softmax`,\n",
    "como métodos para encontrar hiperplanos que separam as diferentes classes de destino.\n",
    "Nesse contexto, esses hiperplanos são freqüentemente chamados de *planos de decisão*.\n",
    "A maioria dos modelos de classificação profundamente aprendidos termina\n",
    "com uma camada linear alimentada em um *softmax*,\n",
    "para que se possa interpretar o papel da rede neural profunda\n",
    "encontrar uma incorporação não linear de modo que as classes de destino\n",
    "podem ser separados de forma limpa por hiperplanos.\n",
    "\n",
    "Para dar um exemplo feito à mão, observe que podemos produzir um modelo razoável\n",
    "para classificar pequenas imagens de camisetas e calças do conjunto de dados do Fashion MNIST\n",
    "(visto em :numref:`sec_fashion_mnist`)\n",
    "apenas pegando o vetor entre seus meios para definir o plano de decisão\n",
    "e olho um limiar bruto. Primeiro, carregaremos os dados e calcularemos as médias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# Load in the dataset\n",
    "trans = []\n",
    "trans.append(transforms.ToTensor())\n",
    "trans = transforms.Compose(trans)\n",
    "train = torchvision.datasets.FashionMNIST(root=\"../data\", transform=trans,\n",
    "                                          train=True, download=True)\n",
    "test = torchvision.datasets.FashionMNIST(root=\"../data\", transform=trans,\n",
    "                                         train=False, download=True)\n",
    "\n",
    "X_train_0 = torch.stack(\n",
    "    [x[0] * 256 for x in train if x[1] == 0]).type(torch.float32)\n",
    "X_train_1 = torch.stack(\n",
    "    [x[0] * 256 for x in train if x[1] == 1]).type(torch.float32)\n",
    "X_test = torch.stack(\n",
    "    [x[0] * 256 for x in test if x[1] == 0 or x[1] == 1]).type(torch.float32)\n",
    "y_test = torch.stack([torch.tensor(x[1]) for x in test\n",
    "                      if x[1] == 0 or x[1] == 1]).type(torch.float32)\n",
    "\n",
    "# Compute averages\n",
    "ave_0 = torch.mean(X_train_0, axis=0)\n",
    "ave_1 = torch.mean(X_train_1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "Pode ser informativo examinar essas médias em detalhes, portanto, vamos representar graficamente sua aparência. Nesse caso, vemos que a média realmente se assemelha a uma imagem borrada de uma camiseta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"168.350558pt\" version=\"1.1\" viewBox=\"0 0 170.025 168.350558\" width=\"170.025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-12-11T06:52:37.698620</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 168.350558 \n",
       "L 170.025 168.350558 \n",
       "L 170.025 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 144.472433 \n",
       "L 162.825 144.472433 \n",
       "L 162.825 8.572433 \n",
       "L 26.925 8.572433 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p769d70aee0)\">\n",
       "    <image height=\"136\" id=\"image5dcc9974c9\" transform=\"scale(1 -1)translate(0 -136)\" width=\"136\" x=\"26.925\" xlink:href=\"data:image/png;base64,\n",
       "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\" y=\"-8.472433\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mc4cf6b2de6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.351786\" xlink:href=\"#mc4cf6b2de6\" y=\"144.472433\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(26.170536 159.070871)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"77.8875\" xlink:href=\"#mc4cf6b2de6\" y=\"144.472433\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(71.525 159.070871)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.423214\" xlink:href=\"#mc4cf6b2de6\" y=\"144.472433\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(120.060714 159.070871)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m974da0d4bc\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m974da0d4bc\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m974da0d4bc\" y=\"35.267076\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 39.066295)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m974da0d4bc\" y=\"59.534933\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 63.334152)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m974da0d4bc\" y=\"83.80279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 87.602009)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m974da0d4bc\" y=\"108.070647\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 111.869866)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m974da0d4bc\" y=\"132.338504\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 136.137723)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 144.472433 \n",
       "L 26.925 8.572433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 162.825 144.472433 \n",
       "L 162.825 8.572433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 144.472433 \n",
       "L 162.825 144.472433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 8.572433 \n",
       "L 162.825 8.572433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p769d70aee0\">\n",
       "   <rect height=\"135.9\" width=\"135.9\" x=\"26.925\" y=\"8.572433\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot average t-shirt\n",
    "d2l.set_figsize()\n",
    "d2l.plt.imshow(ave_0.reshape(28, 28).tolist(), cmap='Greys')\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "No segundo caso, vemos novamente que a média se assemelha a uma imagem borrada de calças.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"168.350558pt\" version=\"1.1\" viewBox=\"0 0 170.025 168.350558\" width=\"170.025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-12-11T06:52:37.842234</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 168.350558 \n",
       "L 170.025 168.350558 \n",
       "L 170.025 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 144.472433 \n",
       "L 162.825 144.472433 \n",
       "L 162.825 8.572433 \n",
       "L 26.925 8.572433 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p8866b4b14f)\">\n",
       "    <image height=\"136\" id=\"image995aa5fcb2\" transform=\"scale(1 -1)translate(0 -136)\" width=\"136\" x=\"26.925\" xlink:href=\"data:image/png;base64,\n",
       "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\" y=\"-8.472433\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m7addfde8b5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.351786\" xlink:href=\"#m7addfde8b5\" y=\"144.472433\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(26.170536 159.070871)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"77.8875\" xlink:href=\"#m7addfde8b5\" y=\"144.472433\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(71.525 159.070871)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.423214\" xlink:href=\"#m7addfde8b5\" y=\"144.472433\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(120.060714 159.070871)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m05295fc1d1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m05295fc1d1\" y=\"10.999219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m05295fc1d1\" y=\"35.267076\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 39.066295)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m05295fc1d1\" y=\"59.534933\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 63.334152)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m05295fc1d1\" y=\"83.80279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 87.602009)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m05295fc1d1\" y=\"108.070647\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 111.869866)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m05295fc1d1\" y=\"132.338504\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 136.137723)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 144.472433 \n",
       "L 26.925 8.572433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 162.825 144.472433 \n",
       "L 162.825 8.572433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 144.472433 \n",
       "L 162.825 144.472433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 8.572433 \n",
       "L 162.825 8.572433 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p8866b4b14f\">\n",
       "   <rect height=\"135.9\" width=\"135.9\" x=\"26.925\" y=\"8.572433\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot average trousers\n",
    "d2l.plt.imshow(ave_1.reshape(28, 28).tolist(), cmap='Greys')\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "Em uma solução totalmente aprendida pela máquina, aprenderíamos o limite do conjunto de dados. Nesse caso, simplesmente analisamos um limite que parecia bom nos dados de treinamento à mão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7870, dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print test set accuracy with eyeballed threshold\n",
    "w = (ave_1 - ave_0).T\n",
    "# '@' is Matrix Multiplication operator in pytorch.\n",
    "predictions = X_test.reshape(2000, -1) @ (w.flatten()) > -1500000\n",
    "\n",
    "# Accuracy\n",
    "torch.mean(predictions.type(y_test.dtype) == y_test, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## Geometria de Transformações Lineares\n",
    "\n",
    "\n",
    "Por meio de :numref:`sec_linear-algebra` e das discussões acima,\n",
    "temos um conhecimento sólido da geometria de vetores, comprimentos e ângulos.\n",
    "No entanto, há um objeto importante que omitimos de discutir,\n",
    "e essa é uma compreensão geométrica das transformações lineares representadas por matrizes. Totalmente internalizando o que as matrizes podem fazer para transformar dados\n",
    "entre dois espaços de dimensões elevadas potencialmente diferentes requer prática significativa,\n",
    "e está além do escopo deste apêndice.\n",
    "No entanto, podemos começar a construir a intuição em duas dimensões.\n",
    "\n",
    "Suponha que temos alguma matriz:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "a & b \\\\ c & d\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Se quisermos aplicar isso a um vetor arbitrário\n",
    "$\\mathbf{v} = [x, y]^\\top$,\n",
    "nós nos multiplicamos e vemos que\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{A}\\mathbf{v} & = \\begin{bmatrix}a & b \\\\ c & d\\end{bmatrix}\\begin{bmatrix}x \\\\ y\\end{bmatrix} \\\\\n",
    "& = \\begin{bmatrix}ax+by\\\\ cx+dy\\end{bmatrix} \\\\\n",
    "& = x\\begin{bmatrix}a \\\\ c\\end{bmatrix} + y\\begin{bmatrix}b \\\\d\\end{bmatrix} \\\\\n",
    "& = x\\left\\{\\mathbf{A}\\begin{bmatrix}1\\\\0\\end{bmatrix}\\right\\} + y\\left\\{\\mathbf{A}\\begin{bmatrix}0\\\\1\\end{bmatrix}\\right\\}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "Isso pode parecer um cálculo estranho,\n",
    "onde algo claro se tornou algo impenetrável.\n",
    "No entanto, isso nos diz que podemos escrever da maneira\n",
    "que uma matriz transforma *qualquer* vetor\n",
    "em termos de como ele transforma *dois vetores específicos*:\n",
    "$[1,0]^\\top$ and $[0,1]^\\top$.\n",
    "Vale a pena considerar isso por um momento.\n",
    "Nós essencialmente reduzimos um problema infinito\n",
    "(o que acontece com qualquer par de números reais)\n",
    "para um finito (o que acontece com esses vetores específicos).\n",
    "Esses vetores são um exemplo de *vetores canônicos*,\n",
    "onde podemos escrever qualquer vetor em nosso espaço\n",
    "como uma soma ponderada desses *vetores canônicos*.\n",
    "\n",
    "Vamos desenhar o que acontece quando usamos a matriz específica\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "-1 & 3\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "Se olharmos para o vetor específico $\\mathbf{v} = [2, -1]^\\top$,\n",
    "vemos que é $2\\cdot[1,0]^\\top + -1\\cdot[0,1]^\\top$,\n",
    "e assim sabemos que a matriz $A$ irá enviar isso para\n",
    "$2(\\mathbf{A}[1,0]^\\top) + -1(\\mathbf{A}[0,1])^\\top = 2[1, -1]^\\top - [2,3]^\\top = [0, -5]^\\top$.\n",
    "Se seguirmos essa lógica com cuidado,\n",
    "digamos, considerando a grade de todos os pares inteiros de pontos,\n",
    "vemos que o que acontece é que a multiplicação da matriz\n",
    "pode inclinar, girar e dimensionar a grade,\n",
    "mas a estrutura da grade deve permanecer como você vê em :numref:`fig_grid-transform`.\n",
    "\n",
    "![A matriz $\\mathbf{A}$ agindo nos vetores de base dados. Observe como toda a grade é transportada junto com ela.](../img/grid-transform.svg)\n",
    ":label:`fig_grid-transform`\n",
    "\n",
    "Este é o ponto intuitivo mais importante\n",
    "para internalizar sobre transformações lineares representadas por matrizes.\n",
    "As matrizes são incapazes de distorcer algumas partes do espaço de maneira diferente de outras.\n",
    "Tudo o que elas podem fazer é pegar as coordenadas originais em nosso espaço\n",
    "e inclinar, girar e dimensioná-las.\n",
    "\n",
    "Algumas distorções podem ser graves. Por exemplo, a matriz\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & -1 \\\\ 4 & -2\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "comprime todo o plano bidimensional em uma única linha.\n",
    "Identificar e trabalhar com essas transformações é o tópico de uma seção posterior,\n",
    "mas geometricamente podemos ver que isso é fundamentalmente diferente\n",
    "dos tipos de transformações que vimos acima.\n",
    "Por exemplo, o resultado da matriz $\\mathbf{A}$ pode ser \"dobrado\" para a grade original. Os resultados da matriz $\\mathbf{B}$ não podem\n",
    "porque nunca saberemos de onde o vetor $[1,2]^\\top$ veio --- estava\n",
    "it $[1,1]^\\top$ ou $[0, -1]^\\top$?\n",
    "\n",
    "Embora esta imagem fosse para uma matriz $2\\times2$,\n",
    "nada nos impede de levar as lições aprendidas para dimensões superiores.\n",
    "Se tomarmos vetores de base semelhantes como $[1,0, \\ldots,0]$\n",
    "e ver para onde nossa matriz os envia,\n",
    "podemos começar a ter uma ideia de como a multiplicação da matriz\n",
    "distorce todo o espaço em qualquer dimensão de espaço com a qual estamos lidando.\n",
    "\n",
    "## Dependência Linear\n",
    "\n",
    "Considere novamente a matriz\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & -1 \\\\ 4 & -2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Isso comprime todo o plano para viver na única linha $y=2x$.\n",
    "A questão agora surge: há alguma maneira de detectarmos isso\n",
    "apenas olhando para a própria matriz?\n",
    "A resposta é que realmente podemos.\n",
    "Tomemos $\\mathbf{b}_1 = [2,4]^\\top$ e $\\mathbf{b}_2 = [-1, -2]^\\top$\n",
    "sejam as duas colunas de $\\mathbf{B}$.\n",
    "Lembre-se de que podemos escrever tudo transformado pela matriz $\\mathbf{B}$\n",
    "como uma soma ponderada das colunas da matriz:\n",
    "como $a_1\\mathbf{b}_1 + a_2\\mathbf{b}_2$.\n",
    "Chamamos isso de *combinação linear*.\n",
    "O fato de $\\mathbf{b}_1 = -2\\cdot\\mathbf{b}_2$\n",
    "significa que podemos escrever qualquer combinação linear dessas duas colunas\n",
    "inteiramente em termos de, digamos, $\\mathbf{b}_2$ desde\n",
    "\n",
    "$$\n",
    "a_1\\mathbf{b}_1 + a_2\\mathbf{b}_2 = -2a_1\\mathbf{b}_2 + a_2\\mathbf{b}_2 = (a_2-2a_1)\\mathbf{b}_2.\n",
    "$$\n",
    "\n",
    "Isso significa que uma das colunas é, de certo modo, redundante\n",
    "porque não define uma direção única no espaço.\n",
    "Isso não deve nos surpreender muito\n",
    "pois já vimos que esta matriz\n",
    "reduz o plano inteiro em uma única linha.\n",
    "Além disso, vemos que a dependência linear\n",
    "$\\mathbf{b}_1 = -2\\cdot\\mathbf{b}_2$ captura isso.\n",
    "Para tornar isso mais simétrico entre os dois vetores, vamos escrever isso como\n",
    "\n",
    "$$\n",
    "\\mathbf{b}_1  + 2\\cdot\\mathbf{b}_2 = 0.\n",
    "$$\n",
    "\n",
    "Em geral, diremos que uma coleção de vetores\n",
    "$\\mathbf{v}_1, \\ldots, \\mathbf{v}_k$ são *linearmente dependentes*\n",
    "se existirem coeficientes $a_1, \\ldots, a_k$ *nem todos iguais a zero* de modo que\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^k a_i\\mathbf{v_i} = 0.\n",
    "$$\n",
    "\n",
    "Neste caso, podemos resolver para um dos vetores\n",
    "em termos de alguma combinação dos outros,\n",
    "e efetivamente torná-lo redundante.\n",
    "Assim, uma dependência linear nas colunas de uma matriz\n",
    "é uma testemunha do fato de que nossa matriz\n",
    "está comprimindo o espaço para alguma dimensão inferior.\n",
    "Se não houver dependência linear, dizemos que os vetores são *linearmente independentes*.\n",
    "Se as colunas de uma matriz são linearmente independentes,\n",
    "nenhuma compressão ocorre e a operação pode ser desfeita.\n",
    "\n",
    "## Classificação\n",
    "\n",
    "Se tivermos uma matriz geral $n\\times m$,\n",
    "é razoável perguntar em qual espaço de dimensão a matriz mapeia.\n",
    "Um conceito conhecido como classificação será a nossa resposta.\n",
    "Na seção anterior, notamos que uma dependência linear\n",
    "testemunha a compressão do espaço em uma dimensão inferior\n",
    "e assim seremos capazes de usar isso para definir a noção de posto.\n",
    "Em particular, a classificação de uma matriz $\\mathbf{A}$\n",
    "é o maior número de colunas linearmente independentes\n",
    "entre todos os subconjuntos de colunas. Por exemplo, a matriz\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & 4 \\\\ -1 & -2\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "tem $\\mathrm{rank}(B)=1$, uma vez que as duas colunas são linearmente dependentes,\n",
    "mas qualquer coluna por si só não é linearmente dependente.\n",
    "Para um exemplo mais desafiador, podemos considerar\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\begin{bmatrix}\n",
    "1& 3 & 0 & -1 & 0 \\\\\n",
    "-1 & 0 & 1 & 1 & -1 \\\\\n",
    "0 & 3 & 1 & 0 & -1 \\\\\n",
    "2 & 3 & -1 & -2 & 1\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "\n",
    "e mostrar que $\\mathbf{C}$ tem classificação dois, uma vez que, por exemplo,\n",
    "as duas primeiras colunas são linearmente independentes,\n",
    "entretanto, qualquer uma das quatro coleções de três colunas é dependente.\n",
    "\n",
    "Este procedimento, conforme descrito, é muito ineficiente.\n",
    "Requer olhar para cada subconjunto das colunas de nossa matriz,\n",
    "e, portanto, é potencialmente exponencial no número de colunas.\n",
    "Mais tarde, veremos uma forma mais eficiente do ponto de vista computacional\n",
    "para calcular a classificação de uma matriz, mas por enquanto,\n",
    "isso é suficiente para ver que o conceito\n",
    "está bem definido e compreende o significado.\n",
    "\n",
    "## Invertibilidade\n",
    "\n",
    "Vimos acima que a multiplicação por uma matriz com colunas linearmente dependentes\n",
    "não pode ser desfeita, ou seja, não há operação inversa que sempre pode recuperar a entrada. No entanto, a multiplicação por uma matriz de classificação completa\n",
    "(ou seja, algum $\\mathbf{A}$ que é $n \\times n$ matriz com classificação $n$),\n",
    "devemos sempre poder desfazê-lo. Considere a matriz\n",
    "\n",
    "$$\n",
    "\\mathbf{I} = \\begin{bmatrix}\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "que é a matriz com uns ao longo da diagonal e zeros em outros lugares.\n",
    "Chamamos isso de matriz de * identidade *.\n",
    "É a matriz que deixa nossos dados inalterados quando aplicados.\n",
    "Para encontrar uma matriz que desfaça o que nossa matriz $\\mathbf{A}$ fez,\n",
    "queremos encontrar uma matriz $\\mathbf{A}^{-1}$ tal que\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{A}\\mathbf{A}^{-1} =  \\mathbf{I}.\n",
    "$$\n",
    "\n",
    "Se olharmos para isso como um sistema, temos $n \\times n$ incógnitas\n",
    "(as entradas de $\\mathbf{A}^{-1}$) e $n \\times n$ equações\n",
    "(a igualdade que precisa ser mantida entre cada entrada do produto $\\mathbf{A}^{-1}\\mathbf{A}$ e cada entrada de $\\mathbf{I}$)\n",
    "portanto, devemos genericamente esperar que exista uma solução.\n",
    "Na verdade, na próxima seção, veremos uma quantidade chamada de *determinante*,\n",
    "que tem a propriedade de que, desde que o determinante não seja zero, podemos encontrar uma solução. Chamamos tal matriz $\\mathbf{A}^{-1}$ de matriz *inversa*.\n",
    "Por exemplo, se $\\mathbf{A}$ é a matriz $2 \\times 2$ geral\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "então podemos ver que a inversa é\n",
    "\n",
    "$$\n",
    " \\frac{1}{ad-bc}  \\begin{bmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Podemos testar para ver isso vendo que a multiplicação\n",
    "pela inversa dado pela fórmula acima funciona na prática.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.tensor([[1, 2], [1, 4]], dtype=torch.float32)\n",
    "M_inv = torch.tensor([[2, -1], [-0.5, 0.5]])\n",
    "M_inv @ M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "### Problemas Numéricos\n",
    "Embora o inverso de uma matriz seja útil em teoria,\n",
    "devemos dizer que na maioria das vezes não desejamos\n",
    "*usar* a matriz inversa para resolver um problema na prática.\n",
    "Em geral, existem algoritmos muito mais estáveis numericamente\n",
    "para resolver equações lineares como\n",
    "\n",
    "$$\n",
    "\\mathbf{A}\\mathbf{x} = \\mathbf{b},\n",
    "$$\n",
    "\n",
    "do que calcular a inversa e multiplicar para obter\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{b}.\n",
    "$$\n",
    "\n",
    "Assim como a divisão por um pequeno número pode levar à instabilidade numérica,\n",
    "o mesmo pode acontecer com a inversão de uma matriz que está perto de ter uma classificação baixa.\n",
    "\n",
    "\n",
    "Além disso, é comum que a matriz $\\mathbf{A}$ seja *esparsa*,\n",
    "o que significa que ele contém apenas um pequeno número de valores diferentes de zero.\n",
    "Se fossemos explorar exemplos, veríamos\n",
    "que isso não significa que o inverso é esparso.\n",
    "Mesmo se $\\mathbf{A}$ fosse uma matriz de $1$ milhão por $1$ milhão\n",
    "com apenas $5$ milhões de entradas diferentes de zero\n",
    "(e, portanto, precisamos apenas armazenar aqueles $5$ milhões),\n",
    "a inversa normalmente terá quase todas as entradas não negativas,\n",
    "exigindo que armazenemos todas as $1\\text{M}^2$ de entradas --- isto é $1$ trilhão de entradas!\n",
    "\n",
    "Embora não tenhamos tempo para mergulhar totalmente nas espinhosas questões numéricas\n",
    "frequentemente encontrados ao trabalhar com álgebra linear,\n",
    "queremos fornecer-lhe alguma intuição sobre quando proceder com cautela,\n",
    "e geralmente evitar a inversão na prática é uma boa regra prática.\n",
    "\n",
    "## Determinante\n",
    "A visão geométrica da álgebra linear oferece uma maneira intuitiva\n",
    "para interpretar uma quantidade fundamental conhecida como *determinante*.\n",
    "Considere a imagem da grade de antes, mas agora com uma região destacada (:numref:`fig_grid-fill`).\n",
    "\n",
    "![A matriz $\\mathbf{A}$ novamente distorcendo a grade. Desta vez, quero chamar a atenção em particular para o que acontece com o quadrado destacado.](../img/grid-transform-filled.svg)\n",
    ":label:`fig_grid-filled`\n",
    "\n",
    "Olhe para o quadrado destacado. Este é um quadrado com bordas fornecidas\n",
    "por $(0, 1)$ e $(1, 0)$ e, portanto, tem área um.\n",
    "Depois que $\\mathbf{A}$ transforma este quadrado,\n",
    "vemos que se torna um paralelogramo.\n",
    "Não há razão para este paralelogramo ter a mesma área\n",
    "com que começamos, e de fato no caso específico mostrado aqui de\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "-1 & 3\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "\n",
    "é um exercício de geometria coordenada para calcular\n",
    "a área deste paralelogramo e obtenha que a área é $5$.\n",
    "\n",
    "Em geral, se tivermos uma matriz\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "\n",
    "podemos ver com alguns cálculos que a área\n",
    "do paralelogramo resultante é $ad-bc$.\n",
    "Essa área é chamada de *determinante*.\n",
    "\n",
    "Vamos verificar isso rapidamente com algum código de exemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.det(torch.tensor([[1, -1], [2, 3]], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "Os olhos de águia entre nós notarão\n",
    "que esta expressão pode ser zero ou mesmo negativa.\n",
    "Para o termo negativo, isso é uma questão de convenção\n",
    "geralmente considerado em matemática:\n",
    "se a matriz inverte a figura,\n",
    "dizemos que a área está negada.\n",
    "Vejamos agora que quando o determinante é zero, aprendemos mais.\n",
    "\n",
    "Vamos considerar\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\begin{bmatrix}\n",
    "2 & 4 \\\\ -1 & -2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "Se calcularmos o determinante desta matriz,\n",
    "obtemos $2\\cdot(-2 ) - 4\\cdot(-1) = 0$.\n",
    "Dado o nosso entendimento acima, isso faz sentido.\n",
    "$\\mathbf{B}$ comprime o quadrado da imagem original\n",
    "até um segmento de linha, que tem área zero.\n",
    "E, de fato, sendo comprimido em um espaço dimensional inferior\n",
    "é a única maneira de ter área zero após a transformação.\n",
    "Assim, vemos que o seguinte resultado é verdadeiro:\n",
    "uma matriz $A$ é invertível se e somente se\n",
    "o determinante não é igual a zero.\n",
    "\n",
    "Como comentário final, imagine que temos alguma figura desenhada no avião.\n",
    "Pensando como cientistas da computação, podemos decompor\n",
    "aquela figura em uma coleção de pequenos quadrados\n",
    "de modo que a área da figura é em essência\n",
    "apenas o número de quadrados na decomposição.\n",
    "Se agora transformarmos essa figura em uma matriz,\n",
    "enviamos cada um desses quadrados para paralelogramos,\n",
    "cada um deles tem área dada pelo determinante.\n",
    "Vemos que para qualquer figura, o determinante dá o número (com sinal)\n",
    "que uma matriz dimensiona a área de qualquer figura.\n",
    "\n",
    "Determinantes de computação para matrizes maiores podem ser trabalhosos,\n",
    "mas a intuição é a mesma.\n",
    "O determinante continua sendo o fator\n",
    "que $n\\times n$ matrizes escalam volumes $n$-dimensionais.\n",
    "\n",
    "## Tensores e Operações de Álgebra Linear Comum\n",
    "\n",
    "\n",
    "Em :numref:`sec_linear-algebra` o conceito de tensores foi introduzido.\n",
    "Nesta seção, vamos mergulhar mais profundamente nas contrações tensoras\n",
    "(o tensor equivalente à multiplicação da matriz),\n",
    "e ver como pode fornecer uma visão unificada\n",
    "em uma série de operações de matriz e vetor.\n",
    "\n",
    "Com matrizes e vetores, sabíamos como multiplicá-los para transformar os dados.\n",
    "Precisamos ter uma definição semelhante para tensores se eles forem úteis para nós.\n",
    "Pense na multiplicação de matrizes:\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\mathbf{A}\\mathbf{B},\n",
    "$$\n",
    "\n",
    "ou equivalente\n",
    "\n",
    "$$ c_{i, j} = \\sum_{k} a_{i, k}b_{k, j}.$$\n",
    "\n",
    "Esse padrão pode ser repetido para tensores.\n",
    "Para tensores, não há um caso de qual\n",
    "para somar isso pode ser universalmente escolhido,\n",
    "portanto, precisamos especificar exatamente quais índices queremos somar.\n",
    "Por exemplo, podemos considerar\n",
    "\n",
    "$$\n",
    "y_{il} = \\sum_{jk} x_{ijkl}a_{jk}.\n",
    "$$\n",
    "\n",
    "\n",
    "Essa transformação é chamada de *contração tensorial*.\n",
    "Pode representar uma família de transformações muito mais flexível\n",
    "que a multiplicação de matriz sozinha.\n",
    "\n",
    "Como uma simplificação de notação frequentemente usada,\n",
    "podemos notar que a soma está exatamente acima desses índices\n",
    "que ocorrem mais de uma vez na expressão,\n",
    "assim, as pessoas costumam trabalhar com *notação de Einstein*,\n",
    "onde o somatório é implicitamente assumido sobre todos os índices repetidos.\n",
    "Isso dá a expressão compacta:\n",
    "\n",
    "$$\n",
    "y_{il} = x_{ijkl}a_{jk}.\n",
    "$$\n",
    "\n",
    "### Exemplos Comuns de Álgebra Linear\n",
    "\n",
    "Vamos ver quantas das definições algébricas lineares\n",
    "que vimos antes pode ser expresso nesta notação de tensor compactado:\n",
    "\n",
    "* $\\mathbf{v} \\cdot \\mathbf{w} = \\sum_i v_iw_i$\n",
    "* $\\|\\mathbf{v}\\|_2^{2} = \\sum_i v_iv_i$\n",
    "* $(\\mathbf{A}\\mathbf{v})_i = \\sum_j a_{ij}v_j$\n",
    "* $(\\mathbf{A}\\mathbf{B})_{ik} = \\sum_j a_{ij}b_{jk}$\n",
    "* $\\mathrm{tr}(\\mathbf{A}) = \\sum_i a_{ii}$\n",
    "\n",
    "Dessa forma, podemos substituir uma miríade de notações especializadas por expressões tensoriais curtas.\n",
    "\n",
    "### Expressando em Código\n",
    "Os tensores também podem ser operados com flexibilidade no código.\n",
    "Conforme visto em :numref:`sec_linear-algebra`,\n",
    "podemos criar tensores como mostrado abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2, 2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tensors\n",
    "B = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "v = torch.tensor([1, 2])\n",
    "\n",
    "# Print out the shapes\n",
    "A.shape, B.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "O somatório de Einstein foi implementado diretamente.\n",
    "Os índices que ocorrem na soma de Einstein podem ser passados como uma *string*,\n",
    "seguido pelos tensores que estão sofrendo ação.\n",
    "Por exemplo, para implementar a multiplicação de matrizes,\n",
    "podemos considerar o somatório de Einstein visto acima\n",
    "($\\mathbf{A}\\mathbf{v} = a_{ij}v_j$)\n",
    "e retirar os próprios índices para obter a implementação:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5, 11]), tensor([ 5, 11]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reimplement matrix multiplication\n",
    "torch.einsum(\"ij, j -> i\", A, v), A@v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "Esta é uma notação altamente flexível.\n",
    "Por exemplo, se quisermos calcular\n",
    "o que seria tradicionalmente escrito como\n",
    "\n",
    "$$\n",
    "c_{kl} = \\sum_{ij} \\mathbf{b}_{ijk}\\mathbf{a}_{il}v_j.\n",
    "$$\n",
    "\n",
    "pode ser implementado via somatório de Einstein como:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 90, 126],\n",
       "        [102, 144],\n",
       "        [114, 162]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ijk, il, j -> kl\", B, A, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "Esta notação é legível e eficiente para humanos,\n",
    "por mais volumoso que seja por algum motivo\n",
    "precisamos gerar uma contração de tensor programaticamente.\n",
    "Por este motivo, `einsum` fornece uma notação alternativa\n",
    "fornecendo índices inteiros para cada tensor.\n",
    "Por exemplo, a mesma contração tensorial também pode ser escrita como:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# PyTorch doesn't support this type of notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "Qualquer uma das notações permite uma representação concisa e eficiente das contrações do tensor no código.\n",
    "\n",
    "## Resumo\n",
    "* Os vetores podem ser interpretados geometricamente como pontos ou direções no espaço.\n",
    "* Os produtos escalares definem a noção de ângulo para espaços de dimensões arbitrariamente altas.\n",
    "* Hiperplanos são generalizações dimensionais de linhas e planos. Eles podem ser usados ​​para definir planos de decisão que geralmente são usados ​​como a última etapa em uma tarefa de classificação.\n",
    "* A multiplicação de matrizes pode ser interpretada geometricamente como distorções uniformes das coordenadas subjacentes. Eles representam uma maneira muito restrita, mas matematicamente limpa, de transformar vetores.\n",
    "* Dependência linear é uma forma de saber quando uma coleção de vetores está em um espaço dimensional inferior do que esperaríamos (digamos que você tenha $3$ vetores vivendo em um espaço $2$-dimensional). A classificação de uma matriz é o tamanho do maior subconjunto de suas colunas que são linearmente independentes.\n",
    "* Quando a inversa de uma matriz é definida, a inversão da matriz nos permite encontrar outra matriz que desfaça a ação da primeira. A inversão da matriz é útil na teoria, mas requer cuidado na prática devido à instabilidade numérica.\n",
    "* Os determinantes nos permitem medir o quanto uma matriz se expande ou contrai em um espaço. Um determinante diferente de zero implica uma matriz invertível (não singular) e um determinante de valor zero significa que a matriz é não invertível (singular).\n",
    "* As contrações do tensor e a soma de Einstein fornecem uma notação limpa e organizada para expressar muitos dos cálculos que são vistos no aprendizado de máquina.\n",
    "\n",
    "## Exercícios\n",
    "1. Qual é o ângulo entre\n",
    "$$\n",
    "\\vec v_1 = \\begin{bmatrix}\n",
    "1 \\\\ 0 \\\\ -1 \\\\ 2\n",
    "\\end{bmatrix}, \\qquad \\vec v_2 = \\begin{bmatrix}\n",
    "3 \\\\ 1 \\\\ 0 \\\\ 1\n",
    "\\end{bmatrix}?\n",
    "$$\n",
    "2. Verdadeiro ou falso: $\\begin{bmatrix}1 & 2\\\\0&1\\end{bmatrix}$ e $\\begin{bmatrix}1 & -2\\\\0&1\\end{bmatrix}$ são inversas uma da outra?\n",
    "3. Suponha que desenhemos uma forma no plano com área $100\\mathrm{m}^2$. Qual é a área depois de transformar a figura pela matriz\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2 & 3\\\\\n",
    "1 & 2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "4. Qual dos seguintes conjuntos de vetores são linearmente independentes?\n",
    " * $\\left\\{\\begin{pmatrix}1\\\\0\\\\-1\\end{pmatrix}, \\begin{pmatrix}2\\\\1\\\\-1\\end{pmatrix}, \\begin{pmatrix}3\\\\1\\\\1\\end{pmatrix}\\right\\}$\n",
    " * $\\left\\{\\begin{pmatrix}3\\\\1\\\\1\\end{pmatrix}, \\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}, \\begin{pmatrix}0\\\\0\\\\0\\end{pmatrix}\\right\\}$\n",
    " * $\\left\\{\\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix}, \\begin{pmatrix}0\\\\1\\\\-1\\end{pmatrix}, \\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix}\\right\\}$\n",
    "5. Suponha que você tenha uma matriz escrita como $A = \\begin{bmatrix}c\\\\d\\end{bmatrix}\\cdot\\begin{bmatrix}a & b\\end{bmatrix}$ para alguma escolha de valores $a, b, c$,e $d$.  Verdadeiro ou falso: o determinante dessa matriz é sempre $0$?\n",
    "6. Os vetores $e_1 = \\begin{bmatrix}1\\\\0\\end{bmatrix}$ e $e_2 = \\begin{bmatrix}0\\\\1\\end{bmatrix}$ são ortogonais. Qual é a condição em uma matriz $A$ para que $Ae_1$ e $Ae_2$ sejam ortogonais?\n",
    "7. Como você pode escrever $\\mathrm{tr}(\\mathbf{A}^4)$ na notação de Einstein para uma matriz arbitrária $A$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussões](https://discuss.d2l.ai/t/1084)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 48
   },
   "source": [
    "<!--stackedit_data:\n",
    "eyJoaXN0b3J5IjpbMTAxMzE4MDU4NywxMTg3NDAzMDQsLTE3OD\n",
    "U3ODgwMzAsLTEwNzY5MTgyNjksNDgyOTc3MjU1LDQyNDEwMDM2\n",
    "MSwxNTk5OTgwNDIwLC03ODc2ODM1ODQsMTIyOTA4NDY4NiwxOT\n",
    "kxODk4NTM4LC0xNjQzNjc4Nzk0LC03NTk4ODE3MDYsMjIyMjc4\n",
    "MTIyLC0zNDg2ODI3MzEsLTkyMzYxMjc1NywxMTk1NzY0MTgxLC\n",
    "0yMTA3MzY0Mzc2LDIxMDI4NzE3ODUsLTczMzAxNjM1OCwtMTU4\n",
    "OTIxMzA2NF19\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}